{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/thebrownviking20/bert-multiclass-classification/notebook#BERT-implementation\n",
    "mport numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "print(os.listdir(\"input\"))\n",
    "import fileinput\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "#from tensorflow.keras.layers.embeddings import Embedding\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_forms = ['am','are','were','was','is','been','being','be']\n",
    "blank = '----'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(tokens):\n",
    "    return [t for t in tokens if t in valid_forms]\n",
    "    \n",
    "def replace_blank(tokens):\n",
    "    return [blank if t in valid_forms else t for t in tokens]\n",
    "\n",
    "def create_windows(tokens, window_size=3):\n",
    "    X = []\n",
    "    for i, word in enumerate(tokens):\n",
    "        if word == blank:\n",
    "            window = tokens[i-window_size:i] + tokens[i+1:i+window_size+1]\n",
    "            window = ' '.join(window)\n",
    "            X.append(window)    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"internet_archive_scifi_v3.txt\",\"r\")\n",
    "a = f1.read()\n",
    "a = re.sub('[\\n]', '', a)\n",
    "tokens = wordpunct_tokenize(a)\n",
    "y = detect(tokens)\n",
    "tokens = replace_blank(tokens)\n",
    "X = create_windows(tokens)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"Text\"] = X\n",
    "df[\"Label\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Publisher Editor IF published bi -</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in this magazine fiction . Any</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to actual persons coincidental . #</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. The title selected after much</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the theory it indicative of the</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Text Label\n",
       "0  Publisher Editor IF published bi -    is\n",
       "1      in this magazine fiction . Any   are\n",
       "2  to actual persons coincidental . #    is\n",
       "3     . The title selected after much   was\n",
       "4     the theory it indicative of the    is"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>am</th>\n",
       "      <th>are</th>\n",
       "      <th>be</th>\n",
       "      <th>been</th>\n",
       "      <th>being</th>\n",
       "      <th>is</th>\n",
       "      <th>was</th>\n",
       "      <th>were</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Publisher Editor IF published bi -</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in this magazine fiction . Any</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to actual persons coincidental . #</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. The title selected after much</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the theory it indicative of the</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Text  am  are  be  been  being  is  was  were\n",
       "0  Publisher Editor IF published bi -   0    0   0     0      0   1    0     0\n",
       "1      in this magazine fiction . Any   0    1   0     0      0   0    0     0\n",
       "2  to actual persons coincidental . #   0    0   0     0      0   1    0     0\n",
       "3     . The title selected after much   0    0   0     0      0   0    1     0\n",
       "4     the theory it indicative of the   0    0   0     0      0   1    0     0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(df[\"Label\"])\n",
    "df.drop(['Label'],axis=1,inplace=True)\n",
    "df = pd.concat([df,one_hot],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 9)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1[\"Text\"].values, df1.drop(['Text'],axis=1).values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train\n",
    "X_test1 = X_test\n",
    "y_train1 = y_train\n",
    "y_test1 = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('field . Reports already coming in',\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valid_forms = ['am','are','were','was','is','been','being','be']\n",
    "X_test[4], y_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 13, 45]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 55, 13, 45])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. \" Where you going ?\"'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[13].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,  74,  13, 483]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(['how you today ?\"'])\n",
    "X_test_testing = pad_sequences(sequences, maxlen=50)\n",
    "X_test_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_testing[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0917 13:12:36.869491 28340 deprecation.py:506] From C:\\Users\\gunawf01\\AppData\\Local\\Continuum\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0917 13:12:37.007591 28340 deprecation.py:506] From C:\\Users\\gunawf01\\AppData\\Local\\Continuum\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 100, input_length=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0917 13:13:38.673088 28340 deprecation.py:323] From C:\\Users\\gunawf01\\AppData\\Local\\Continuum\\anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "144000/144000 [==============================] - 320s 2ms/sample - loss: 1.3027 - acc: 0.5350 - val_loss: 0.8172 - val_acc: 0.7035\n",
      "Epoch 2/10\n",
      "144000/144000 [==============================] - 318s 2ms/sample - loss: 0.7240 - acc: 0.7316 - val_loss: 0.7145 - val_acc: 0.7297\n",
      "Epoch 3/10\n",
      "144000/144000 [==============================] - 261s 2ms/sample - loss: 0.6067 - acc: 0.7722 - val_loss: 0.6908 - val_acc: 0.7391\n",
      "Epoch 4/10\n",
      "144000/144000 [==============================] - 195s 1ms/sample - loss: 0.5295 - acc: 0.8027 - val_loss: 0.6980 - val_acc: 0.7392\n",
      "Epoch 5/10\n",
      "144000/144000 [==============================] - 194s 1ms/sample - loss: 0.4682 - acc: 0.8267 - val_loss: 0.7187 - val_acc: 0.7393\n",
      "Epoch 6/10\n",
      "144000/144000 [==============================] - 194s 1ms/sample - loss: 0.4171 - acc: 0.8460 - val_loss: 0.7479 - val_acc: 0.7344\n",
      "Epoch 7/10\n",
      "144000/144000 [==============================] - 205s 1ms/sample - loss: 0.3717 - acc: 0.8627 - val_loss: 0.7847 - val_acc: 0.7300\n",
      "Epoch 8/10\n",
      "144000/144000 [==============================] - 190s 1ms/sample - loss: 0.3363 - acc: 0.8777 - val_loss: 0.8237 - val_acc: 0.7240\n",
      "Epoch 9/10\n",
      "144000/144000 [==============================] - 190s 1ms/sample - loss: 0.3047 - acc: 0.8889 - val_loss: 0.8567 - val_acc: 0.7222\n",
      "Epoch 10/10\n",
      "144000/144000 [==============================] - 191s 1ms/sample - loss: 0.2796 - acc: 0.8986 - val_loss: 0.8998 - val_acc: 0.7255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168fc3a5da0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "                    batch_size=1024,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 221us/sample - loss: 0.9046 - acc: 0.7257\n",
      "Test accuracy: 0.72565\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=256, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.8679218e-01, 2.5310742e-03, 1.7630089e-03, ..., 1.0599068e-02,\n",
       "        9.6763194e-02, 7.5688004e-04],\n",
       "       [1.2780123e-07, 1.1998489e-07, 9.9985087e-01, ..., 1.4259963e-05,\n",
       "        7.6977922e-05, 7.8345138e-06],\n",
       "       [1.8735274e-04, 3.8915399e-01, 1.3187789e-05, ..., 1.1678348e-04,\n",
       "        1.4086851e-03, 6.0909170e-01],\n",
       "       ...,\n",
       "       [4.8492208e-02, 2.0528250e-04, 4.0013092e-03, ..., 1.6399462e-02,\n",
       "        9.0137970e-01, 8.7342842e-04],\n",
       "       [1.1335555e-06, 5.6259778e-06, 9.9914002e-01, ..., 4.1221973e-04,\n",
       "        4.1980216e-05, 9.3248409e-06],\n",
       "       [5.6081103e-07, 1.3757233e-05, 9.7657219e-05, ..., 2.8788078e-05,\n",
       "        9.3653571e-06, 4.6974142e-06]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.60      0.60       486\n",
      "          1       0.53      0.50      0.52      2889\n",
      "          2       0.93      0.94      0.93      6128\n",
      "          3       0.93      0.95      0.94      3336\n",
      "          4       0.45      0.28      0.35       765\n",
      "          5       0.53      0.45      0.48      5911\n",
      "          6       0.75      0.81      0.77     15788\n",
      "          7       0.60      0.60      0.60      4697\n",
      "\n",
      "avg / total       0.72      0.73      0.72     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test,axis=1),np.argmax(preds,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model_text_classification.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model_text_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.6864458e-04, 2.6556388e-01, 5.5139052e-04, 2.8467458e-04,\n",
       "       6.6631177e-04, 1.9748784e-03, 8.2585225e-03, 7.2223175e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valid_forms = ['am','are','were','was','is','been','being','be']\n",
    "valid_forms[np.argmax(preds[7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Tokenizer i.e. Vocabulary\n",
    "import pickle\n",
    "with open('TextClassification.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "import pickle\n",
    "with open('TextClassification.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   9, 166,  10, 481]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(['Of course. I sorry'])\n",
    "X_test_testing = pad_sequences(sequences, maxlen=50)\n",
    "X_test_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3116577e-01, 2.8652309e-03, 3.0756216e-03, 3.0108052e-04,\n",
       "        3.8060308e-03, 4.6187039e-02, 2.1202692e-01, 5.7228870e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1 = model.predict(X_test_testing)\n",
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_forms[np.argmax(preds1[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
